<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title> â€“ Concepts</title>
    <link>https://docs.storageos.com/docs/concepts/</link>
    <description>Recent content in Concepts on </description>
    <generator>Hugo -- gohugo.io</generator>
    
	  <atom:link href="https://docs.storageos.com/docs/concepts/index.xml" rel="self" type="application/rss+xml" />
    
    
      
        
      
    
    
    <item>
      <title>Docs: Architecture</title>
      <link>https://docs.storageos.com/docs/concepts/architecture/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://docs.storageos.com/docs/concepts/architecture/</guid>
      <description>
        
        
        &lt;p&gt;StorageOS is a software-defined storage platform for running stateful
applications in Kubernetes.&lt;/p&gt;
&lt;p&gt;Fundamentally, StorageOS uses the storage attached to the nodes in the
StorageOS cluster to create and present virtual volumes into containers. Space
on the host is consumed from the mount point &lt;code&gt;/var/lib/storageos/data&lt;/code&gt;, so it
is therefore recommended that disk devices are used exclusively for StorageOS,
as described in &lt;a href=&#34;https://docs.storageos.com/docs/operations/managing-host-storage/&#34;&gt;Managing Host Storage &lt;/a&gt;&lt;/p&gt;
&lt;p&gt;StorageOS is agnostic to the underlying storage and runs equally well on
bare metal, in virtual machines or on cloud providers.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://docs.storageos.com/images/docs/concepts/storageos-cluster.png&#34; alt=&#34;StorageOS architecture&#34;&gt;&lt;/p&gt;
&lt;p&gt;Read about &lt;a href=&#34;https://storageos.com/storageos-cloud-native-storage&#34;&gt;the cloud native storage principles behind
StorageOS&lt;/a&gt;.&lt;/p&gt;
&lt;h3 id=&#34;storageos-on-kubernetes&#34;&gt;StorageOS on Kubernetes&lt;/h3&gt;
&lt;p&gt;StorageOS is architected as a series of containers that fulfil separate,
discrete functions.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;StorageOS Controlplane&lt;/p&gt;
&lt;p&gt;Responsible for monitoring and maintaining the state of volumes and nodes in the cluster&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;StorageOS Dataplane&lt;/p&gt;
&lt;p&gt;Responsible for all I/O path related tasks; reading, writing, compression and caching&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;StorageOS Scheduler&lt;/p&gt;
&lt;p&gt;Responsible for scheduling applications on the same node as applications volume&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;CSI helper&lt;/p&gt;
&lt;p&gt;Responsible for registering StorageOS with Kubernetes as a CSI driver&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;StorageOS Operator&lt;/p&gt;
&lt;p&gt;Responsible for the creation and maintenance of the StorageOS cluster&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;StorageOS is deployed by the StorageOS operator. In Kubernetes, the StorageOS
Controlplane and Dataplane are deployed in a single pod managed by a daemonset.
This daemonset runs on every node in the cluster that will consume or present
storage. The scheduler, CSI helper and Operator run as separate pods and are
controlled as deployments.&lt;/p&gt;
&lt;p&gt;StorageOS is designed to feel familiar to Kubernetes and Docker users. Storage
is managed through standard StorageClasses and PersistentVolumeClaims, and
&lt;a href=&#34;https://docs.storageos.com/docs/reference/labels/&#34;&gt;features&lt;/a&gt; are controlled by
Kubernetes-style labels and selectors, prefixed with &lt;code&gt;storageos.com/&lt;/code&gt;. By
default, volumes are cached to improve read performance and compressed to
reduce network traffic.&lt;/p&gt;
&lt;p&gt;Any pod may mount a StorageOS virtual volume from any node that is also
running StorageOS, regardless of whether the pod and volume are
collocated on the same node. Therefore, applications may be started or
restarted on any node and access volumes transparently.&lt;/p&gt;

      </description>
    </item>
    
    <item>
      <title>Docs: Clusters</title>
      <link>https://docs.storageos.com/docs/concepts/clusters/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://docs.storageos.com/docs/concepts/clusters/</guid>
      <description>
        
        
        &lt;p&gt;StorageOS clusters represent groups of nodes which run a common distributed
control plane.&lt;/p&gt;
&lt;p&gt;Typically, a StorageOS cluster maps one-to-one to a Kubernetes (or similar
orchestrator) cluster, and we expect our daemonset to run on all worker
nodes within the cluster that will consume or present storage.&lt;/p&gt;
&lt;p&gt;Clusters use etcd to maintain state and manage distributed consensus between
nodes.&lt;/p&gt;

      </description>
    </item>
    
    <item>
      <title>Docs: Compression</title>
      <link>https://docs.storageos.com/docs/concepts/compression/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://docs.storageos.com/docs/concepts/compression/</guid>
      <description>
        
        
        &lt;p&gt;StorageOS compression is handled on a per volume basis and is enabled by
default, as performance is generally increased when compression is enabled due
to fewer read/write operations taking place on the backend store (the volumes&amp;rsquo;
&lt;a href=&#34;https://docs.storageos.com/docs/concepts/volumes#blob-files&#34;&gt;blob files&lt;/a&gt;). Compression can be disabled
by setting the &lt;a href=&#34;https://docs.storageos.com/docs/reference/labels&#34;&gt;label&lt;/a&gt; &lt;code&gt;storageos.com/nocompress=true&lt;/code&gt;
on a volume.&lt;/p&gt;
&lt;p&gt;StorageOS utilises the &lt;a href=&#34;https://lz4.github.io/lz4/&#34;&gt;lz4 compression algorithm&lt;/a&gt;
when writing to the backend store and when compressing &lt;a href=&#34;https://docs.storageos.com/docs/concepts/replication&#34;&gt;replication
traffic&lt;/a&gt; before it is sent across the network.
Compression is granular per 4k block and data will remain
compressed/uncompressed once written to a volume. Therefore, compression can be
dynamically enabled and disabled by setting the &lt;code&gt;storageos.com/nocompress&lt;/code&gt;
label on a volume.&lt;/p&gt;
&lt;p&gt;StorageOS detects whether a block can be compressed or not by creating a
heuristic that predicts the size of a compressed block. If the heuristic
indicates that the compressed block is likely to be larger than the
original block then the uncompressed block is stored. Block size increases post
compression if the compression dictionary is added to a block that cannot be
compressed. By verifying whether blocks can be compressed, disk efficiency is
increased and CPU resources are not wasted on attempts to compress
uncompressible blocks. StorageOS&amp;rsquo; patented on disk format is used to tell
whether individual blocks are compressed without overhead. As such volume
compression can be dynamically enabled/disabled even while a volume is in use.&lt;/p&gt;
&lt;p&gt;When compression and &lt;a href=&#34;https://docs.storageos.com/docs/concepts/encryption&#34;&gt;encryption&lt;/a&gt; are both enabled
for a volume, blocks are compressed then encrypted.&lt;/p&gt;

      </description>
    </item>
    
    <item>
      <title>Docs: Etcd</title>
      <link>https://docs.storageos.com/docs/concepts/etcd/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://docs.storageos.com/docs/concepts/etcd/</guid>
      <description>
        
        
        &lt;p&gt;&lt;a href=&#34;https://etcd.io&#34;&gt;Etcd&lt;/a&gt; is an open-source distributed, strongly consistent key
value store that is used by StorageOS to durably persist the StorageOS cluster
state. As the backing store for Kubernetes, StorageOS uses etcd for many of the
same reasons.&lt;/p&gt;
&lt;p&gt;StorageOS uses etcd as the single source of truth for all StorageOS objects.
Whenever a request is made to create, update or delete an object the result is
written to etcd before the request is completed. Using etcd as a configuration
store allows nodes to retrieve the current cluster state after being offlined,
allowing offlined nodes to rejoin the cluster.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;N.B. StorageOS v2.0 does not provide an embedded etcd server as previous
versions did. You will need to setup an etcd server for StorageOS to use
prior to installation of StorageOS. Please see our &lt;a href=&#34;https://docs.storageos.com/docs/prerequisites/etcd/&#34;&gt;etcd prerequisites&lt;/a&gt; page for more information on how
to install and configure etcd.&lt;/p&gt;
&lt;/blockquote&gt;

      </description>
    </item>
    
    <item>
      <title>Docs: Namespaces</title>
      <link>https://docs.storageos.com/docs/concepts/namespaces/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://docs.storageos.com/docs/concepts/namespaces/</guid>
      <description>
        
        
        &lt;p&gt;StorageOS namespaces are an identical concept to Kubernetes namespaces. They
are intended to allow a StorageOS cluster to be used by multiple teams across
multiple projects.&lt;/p&gt;
&lt;p&gt;It is not necessary to create StorageOS namespaces manually, as StorageOS maps
Kubernetes namespaces on a one-to-one basis when PersistentVolumeClaims using
the StorageOS StorageClass are created.&lt;/p&gt;
&lt;p&gt;Access to Namespaces is controlled through user or group level &lt;a href=&#34;https://docs.storageos.com/docs/concepts/policies/&#34;&gt;policies&lt;/a&gt;.&lt;/p&gt;

      </description>
    </item>
    
    <item>
      <title>Docs: Nodes</title>
      <link>https://docs.storageos.com/docs/concepts/nodes/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://docs.storageos.com/docs/concepts/nodes/</guid>
      <description>
        
        
        &lt;p&gt;A StorageOS node is any machine (virtual or physical) that is running the
StorageOS daemonset pod. A node must be running a daemonset pod in order to
consume and/or present storage.&lt;/p&gt;
&lt;p&gt;By default StorageOS nodes run in &lt;code&gt;hyperconverged&lt;/code&gt; mode. This means that the
node hosts data from StorageOS volumes and can present volumes to applications.&lt;/p&gt;
&lt;p&gt;Alternatively, a node can run in &lt;code&gt;computeonly&lt;/code&gt; mode, which means no storage is
consumed on the node itself and the node only presents volumes hosted by
other nodes. Volumes presented to applications running on compute only nodes
are therefore all remote. Compute only nodes can be very useful for topologies
where nodes are ephemeral and should not host data, but the ephemeral nodes
host applications that require StorageOS volumes. The nodes that are not
intended to hold data, but just to present StorageOS volumes, can be set as
&lt;code&gt;computeonly&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;A node can be marked as compute only at any point in time by adding the label
&lt;code&gt;storageos.com/computeonly=true&lt;/code&gt;, following the &lt;a href=&#34;https://docs.storageos.com/docs/reference/labels/&#34;&gt;labels reference&lt;/a&gt;.&lt;/p&gt;

      </description>
    </item>
    
    <item>
      <title>Docs: Policies</title>
      <link>https://docs.storageos.com/docs/concepts/policies/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://docs.storageos.com/docs/concepts/policies/</guid>
      <description>
        
        
        &lt;p&gt;StorageOS policies are a way to control user and group access to StorageOS
&lt;a href=&#34;https://docs.storageos.com/docs/concepts/namespaces/&#34;&gt;Namespaces&lt;/a&gt;. To grant a user or group
access to a namespace, a policy needs to be created mapping the user or group
to the namespace.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Note: Users always have access to the default namespace&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;For more information on how to use policies, see the
&lt;a href=&#34;https://docs.storageos.com/docs/operations/policies/&#34;&gt;Policies operations&lt;/a&gt; page.&lt;/p&gt;

      </description>
    </item>
    
    <item>
      <title>Docs: Replication</title>
      <link>https://docs.storageos.com/docs/concepts/replication/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://docs.storageos.com/docs/concepts/replication/</guid>
      <description>
        
        
        &lt;p&gt;StorageOS replicates volumes across nodes for data protection and high
availability. Synchronous replication ensures strong consistency for
applications such as databases and Elasticsearch, incurring one network round
trip on writes.&lt;/p&gt;
&lt;p&gt;The basic model for StorageOS replication is of a master volume with distributed
replicas. Each volume can be replicated between 0 and 5 times, which are
provisioned to 0 to 5 nodes, up to the number of remaining nodes in the cluster.&lt;/p&gt;
&lt;p&gt;In this diagram, the master volume &lt;code&gt;D&lt;/code&gt; was created on node 1, and two replicas,
&lt;code&gt;D2&lt;/code&gt; and &lt;code&gt;D3&lt;/code&gt; on nodes 3 and 5.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://docs.storageos.com/images/docs/concepts/high-availability.png&#34; alt=&#34;StorageOS replication&#34;&gt;&lt;/p&gt;
&lt;p&gt;Writes that come into &lt;code&gt;D&lt;/code&gt; (step 1) are written in parallel to &lt;code&gt;D2&lt;/code&gt; and &lt;code&gt;D3&lt;/code&gt;
(step 2). When both replicas and the master acknowledge that the data has been
written (step 3), the write operation return successfully to the application
(step 4).&lt;/p&gt;
&lt;p&gt;For most applications, one replica is sufficient (&lt;code&gt;storageos.com/replicas=1&lt;/code&gt;).&lt;/p&gt;
&lt;p&gt;All replication traffic on the wire is compressed using the lz4 algorithm, then
streamed over tcp/ip to target port tcp/5703.&lt;/p&gt;
&lt;p&gt;If the master volume is lost, a replica is promoted to master (&lt;code&gt;D2&lt;/code&gt; or &lt;code&gt;D3&lt;/code&gt;
above) and a new replica is created and synced on an available node (Node 2 or
4). This is transparent to the application and does not cause downtime.&lt;/p&gt;
&lt;p&gt;If a replica volume is lost and there are enough remaining nodes, a new replica
is created and synced on an available node. While a new replica is created and
being synced, the volume&amp;rsquo;s health will be marked as degraded.&lt;/p&gt;
&lt;p&gt;If the lost replica comes back online before the new replica has finished
synchronizing, then StorageOS will calculate which of the two synchronizing
replicas has the smallest difference compared to the master volume and keep
that replica. The same holds true if a master volume is lost and a replica is
promoted to be the new master. If possible, a new replica will be created and
begin to sync. Should the former master come back online it will be demoted to
a replica and the replica will the smallest difference to the current master
will be kept.&lt;/p&gt;
&lt;p&gt;While the replica count is controllable on a per-volume basis, some
environments may prefer to set &lt;a href=&#34;https://docs.storageos.com/docs/reference/labels/#storageos-storageclass-labels&#34;&gt;default labels on the StorageClass&lt;/a&gt;.&lt;/p&gt;
&lt;h3 id=&#34;delta-sync&#34;&gt;Delta Sync&lt;/h3&gt;
&lt;p&gt;StorageOS implements a delta sync between a volume master and its replicas.
This means that if a replica for a volume goes offline, that when the replica
comes back online only the regions with changed blocks need to be synchronized.
This optimization reduces the time it takes for replicas to catch up, improving
volume resilience. Additionally, it reduces network and IO bandwidth which can
reduce costs when running in public clouds.&lt;/p&gt;

      </description>
    </item>
    
    <item>
      <title>Docs: Volumes</title>
      <link>https://docs.storageos.com/docs/concepts/volumes/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://docs.storageos.com/docs/concepts/volumes/</guid>
      <description>
        
        
        &lt;p&gt;StorageOS volumes are a logical construct which represent a writeable volume
and exhibit standard POSIX semantics. StorageOS presents volumes as mounts into
containers via the Linux LIO subsystem.&lt;/p&gt;
&lt;p&gt;Conceptually, StorageOS volumes have a frontend presentation, which is the
what the application sees, and a backend presentation, which is the actual
on-disk format. Depending on the configuration, frontend and backend components
may be on the same or different hosts.&lt;/p&gt;
&lt;p&gt;Volumes are formatted using the linux standard ext4 filesystem by default.
Kubernetes users may change the default filesystem type to ext2, ext3, ext4,
or xfs by setting the fsType parameter in their StorageClass (See
&lt;a href=&#34;https://docs.storageos.com/docs/reference/filesystems#persistent-volume-filesystems&#34;&gt;Supported
Filesystems&lt;/a&gt; for
more information). Different filesystems may be supported in the future.&lt;/p&gt;
&lt;p&gt;StorageOS volumes are represented on disk in two parts. Actual volume data is
written to blob files in &lt;code&gt;/var/lib/storageos/data/dev[\d+]&lt;/code&gt;. Inside these
directories, each StorageOS block device gets two blob files of the form
&lt;code&gt;vol.xxxxxx.y.blob&lt;/code&gt;, where x is the inode number for the device, and y is an
index between 0 and 1. We provide two blob files in order to ensure that
certain operations which require locking do not impede in-flight writes to the
volume.&lt;/p&gt;
&lt;p&gt;In systems which have multiple &lt;code&gt;/var/lib/storageos/data/dev[\d+]&lt;/code&gt; directories,
two blob files are created per block device. This allows us to load-balance
writes across multiple devices. In cases where dev directories are added after
a period of run time, later directories are favoured for writes until the data
is distributed evenly across the blob files.&lt;/p&gt;
&lt;p&gt;Metadata is kept in directories named &lt;code&gt;/var/lib/storageos/data/db[\d+]&lt;/code&gt;. We
maintain an index of all blocks written to the blob file inside the metadata
store, including checksums. These checksums allow us to detect bitrot, and
return errors on reads, rather than serve bad data. In future versions we may
implement recovery from replicas for volumes with one or more replicas defined.&lt;/p&gt;
&lt;p&gt;StorageOS metadata requires approximately 2.7GB of storage per 1TB of allocated
blocks in the associated volume. This size is consistent irrespective of data
compression defined on the volume.&lt;/p&gt;
&lt;p&gt;To ensure deterministic performance, individual StorageOS volumes must fit on a single
node.&lt;/p&gt;
&lt;h2 id=&#34;volume-resize&#34;&gt;Volume Resize&lt;/h2&gt;
&lt;p&gt;StorageOS v2.1 supports offline resize of volumes. This means that a volume
cannot be resized while it is in use. Furthermore, in order for a resize
operation to take place the volume must not be attached to a node. This is to
ensure that the volume is not in use.&lt;/p&gt;
&lt;p&gt;This means that if a Kubernetes pod is currently consuming a volume that a
resize request has been issued for, the resize will not be actioned until the
pod is terminated and the volume is detached from the node. The StorageOS
controlplane will then attach the volume to the node that holds the master
deployment and resize the underlying block device and then run resize2fs to
expand the filesystem.&lt;/p&gt;
&lt;p&gt;For a walk through of how to resize a volume please see the &lt;a href=&#34;https://docs.storageos.com/docs/operations/resize&#34;&gt;Volume
Resize&lt;/a&gt; operations page.&lt;/p&gt;

      </description>
    </item>
    
  </channel>
</rss>
